{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import math\n",
    "from random import choice\n",
    "from selenium.webdriver.common.proxy import *\n",
    "\n",
    "def get_proxy():\n",
    "    html = requests.get('https://free-proxy-list.net/',headers={'User-Agent': UserAgent().firefox}).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    trs = soup.find('table', id='proxylisttable').find_all('tr')[1:11]\n",
    "\n",
    "    proxies = []\n",
    "\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        if 'yes' in tds[6].text.strip():\n",
    "            ip = tds[0].text.strip()\n",
    "            port = tds[1].text.strip()\n",
    "            schema = 'https' if 'yes' in tds[6].text.strip() else 'http'\n",
    "            proxy = {'schema': schema, 'address': ip + ':' + port}\n",
    "            proxies.append(proxy)\n",
    "\n",
    "    return choice(proxies)\n",
    "\n",
    "def get_html(url, browser):\n",
    "    browser.get(url)\n",
    "    requiredHtml = browser.page_source\n",
    "    #r = requests.get(url,headers={'User-Agent': UserAgent().chrome})\n",
    "    return requiredHtml\n",
    "\n",
    "def numfromstr(s):\n",
    "    l = len(s)\n",
    "    i = 0\n",
    "    s_int = ''\n",
    "    while i < l:\n",
    "        if '0' <= s[i] <= '9':\n",
    "            s_int += s[i]\n",
    "        i = i + 1\n",
    "    if s_int:\n",
    "        return float(s_int)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_list(url, browser):\n",
    "    soup = BeautifulSoup(get_html(url, browser), 'lxml')\n",
    "    num_items = int(soup.find('span', class_=\"total many\").span.text)\n",
    "    num_pages = min(50,math.ceil(num_items/100))\n",
    "    print(num_pages)\n",
    "    divs = soup.find_all('div', class_=\"dtList i-dtList j-card-item\")\n",
    "    links = []\n",
    "    for d in divs:\n",
    "        link = d.find('a', class_=\"ref_goods_n_p\")['href'].strip()\n",
    "        links.append(link)\n",
    "\n",
    "\n",
    "    if num_pages > 1:\n",
    "        for page in range(2,num_pages+1):\n",
    "            soup = BeautifulSoup(get_html(url + '&page=' + str(page), browser), 'lxml')\n",
    "            divs = soup.find_all('div', class_=\"dtList i-dtList j-card-item\")\n",
    "            for d in divs:\n",
    "                link = d.find('a', class_=\"ref_goods_n_p\")['href'].strip()\n",
    "                links.append(link)\n",
    "        \n",
    "    return links   \n",
    "\n",
    "def get_item(html, browser):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    article=soup.find('span', class_='j-article').text.strip()\n",
    "    name=soup.find('span', class_='name').text.strip()\n",
    "    brand=soup.find('span', class_='brand').text.strip()\n",
    "    price = numfromstr(soup.find('span', class_='final-cost').text.strip())\n",
    "    orders_count = numfromstr(soup.find('span', class_='j-orders-count').text.strip())\n",
    "    comments = int(soup.find('a', id=\"comments_reviews_link\").i.text.strip())\n",
    "    rating = int(soup.find('div', class_=\"product-rating\").p.text.strip())\n",
    "    #first_comment = soup.find('div', class_=\"time text-base-gray\").p.text.strip()\n",
    "    browser.find_element_by_link_text('дате').click()\n",
    "    first_comment = browser.find_element_by_class_name('time.text-base-gray').get_attribute('content')\n",
    "    \n",
    "    item = {'article': article, 'brand': brand,'name': name,  'price': price,  'comments': comments,  'orders_count': orders_count,  'rating': rating,  'first_comment': first_comment}\n",
    "    return item\n",
    "\n",
    "def main():\n",
    "    url = 'https://www.wildberries.ru/catalog/0/search.aspx?kind=2&subject=4&search=%D0%BA%D1%83%D0%BF%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%BA%20%D0%B6%D0%B5%D0%BD%D1%81%D0%BA%D0%B8%D0%B9&sort=popular'\n",
    "\n",
    "    # путь к драйверу chrome\n",
    "    firefoxdriver = 'C:\\Work\\drive\\geckodriver.exe'\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.headless = True\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    profile.set_preference(\"general.useragent.override\", UserAgent().random)\n",
    "    \n",
    "    PROXY = get_proxy()['address']\n",
    "    print(PROXY)\n",
    "    \n",
    "    proxy = Proxy({\n",
    "        'proxyType': ProxyType.MANUAL,\n",
    "        'httpProxy': PROXY,\n",
    "        'ftpProxy': PROXY,\n",
    "        'sslProxy': PROXY,\n",
    "        'noProxy':''})\n",
    "    \n",
    "    \n",
    "    browser = webdriver.Firefox(executable_path=firefoxdriver, options=options, proxy=proxy, firefox_profile=profile) \n",
    "    \n",
    "    # you have to use remote, otherwise you'll have to code it yourself in python to \n",
    "    #browser = webdriver.Remote(\"http://localhost:4444/wd/hub\", webdriver.DesiredCapabilities.FIREFOX)\n",
    "\n",
    "\n",
    "    \n",
    "    links = pd.read_csv('links.csv',header=None)[0].tolist()\n",
    "    links = links[:10]\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    items = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        item = get_item(get_html(link, browser), browser)\n",
    "        #print(item)\n",
    "        items.append(item)\n",
    "        i+=1\n",
    "        if i == int(i/100):\n",
    "            df = pd.DataFrame(items)\n",
    "            df['link']=links\n",
    "            df.to_excel('parsing.xlsx')\n",
    "            print(i)\n",
    "            browser.close()\n",
    "            PROXY = get_proxy()['address']\n",
    "            proxy = Proxy({\n",
    "                'proxyType': ProxyType.MANUAL,\n",
    "                'httpProxy': PROXY,\n",
    "                'ftpProxy': PROXY,\n",
    "                'sslProxy': PROXY,\n",
    "                'noProxy':''})\n",
    "            browser = webdriver.Firefox(executable_path=firefoxdriver, options=options, proxy=proxy, firefox_profile=profile)\n",
    "            \n",
    "    df = pd.DataFrame(items)\n",
    "    df['link']=links\n",
    "    df.to_excel('parsing.xlsx')\n",
    "    \n",
    "    #print(len(links))\n",
    "    #print(links[:10])\n",
    "    \n",
    "    browser.close()\n",
    "    \n",
    "    \n",
    "def save_list():\n",
    "    url = 'https://www.wildberries.ru/catalog/0/search.aspx?kind=2&subject=4&search=%D0%BA%D1%83%D0%BF%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%BA%20%D0%B6%D0%B5%D0%BD%D1%81%D0%BA%D0%B8%D0%B9&sort=popular'\n",
    "\n",
    "    # путь к драйверу chrome\n",
    "    firefoxdriver = 'C:\\Work\\drive\\geckodriver.exe'\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.headless = True\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    profile.set_preference(\"general.useragent.override\", UserAgent().random)\n",
    "\n",
    "    \n",
    "    PROXY = get_proxy()['address']\n",
    "    print(PROXY)\n",
    "    \n",
    "    proxy = Proxy({\n",
    "        'proxyType': ProxyType.MANUAL,\n",
    "        'httpProxy': PROXY,\n",
    "        'ftpProxy': PROXY,\n",
    "        'sslProxy': PROXY,\n",
    "        'noProxy':''})\n",
    "    \n",
    "    browser = webdriver.Firefox(executable_path=firefoxdriver, options=options, proxy=proxy, firefox_profile=profile) \n",
    "    \n",
    "    \n",
    "    links = get_list(url, browser)\n",
    "    \n",
    "    df = pd.DataFrame(links).to_csv('links2.csv', index=False, header=False)\n",
    "\n",
    "    browser.close()     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proxy():\n",
    "    html = requests.get('https://free-proxy-list.net/',headers={'User-Agent': UserAgent().firefox}).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    trs = soup.find('table', id='proxylisttable').find_all('tr')[1:11]\n",
    "\n",
    "    proxies = []\n",
    "\n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        if 'yes' in tds[6].text.strip():\n",
    "            ip = tds[0].text.strip()\n",
    "            port = tds[1].text.strip()\n",
    "            schema = 'https' if 'yes' in tds[6].text.strip() else 'http'\n",
    "            proxy = {'schema': schema, 'address': ip + ':' + port}\n",
    "            proxies.append(proxy)\n",
    "\n",
    "    return choice(proxies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url, browser):\n",
    "    browser.get(url)\n",
    "    requiredHtml = browser.page_source\n",
    "    #r = requests.get(url,headers={'User-Agent': UserAgent().chrome})\n",
    "    return requiredHtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numfromstr(s):\n",
    "    l = len(s)\n",
    "    i = 0\n",
    "    s_int = ''\n",
    "    while i < l:\n",
    "        if '0' <= s[i] <= '9':\n",
    "            s_int += s[i]\n",
    "        i = i + 1\n",
    "    if s_int:\n",
    "        return float(s_int)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(url, browser):\n",
    "    soup = BeautifulSoup(get_html(url, browser), 'lxml')\n",
    "    num_items = int(soup.find('span', class_=\"total many\").span.text)\n",
    "    num_pages = min(50,math.ceil(num_items/100))\n",
    "    print(num_pages)\n",
    "    divs = soup.find_all('div', class_=\"dtList i-dtList j-card-item\")\n",
    "    links = []\n",
    "    for d in divs:\n",
    "        link = d.find('a', class_=\"ref_goods_n_p\")['href'].strip()\n",
    "        links.append(link)\n",
    "\n",
    "\n",
    "    if num_pages > 1:\n",
    "        for page in range(2,num_pages+1):\n",
    "            soup = BeautifulSoup(get_html(url + '&page=' + str(page), browser), 'lxml')\n",
    "            divs = soup.find_all('div', class_=\"dtList i-dtList j-card-item\")\n",
    "            for d in divs:\n",
    "                link = d.find('a', class_=\"ref_goods_n_p\")['href'].strip()\n",
    "                links.append(link)\n",
    "        \n",
    "    return links     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item(html, browser):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    article=soup.find('span', class_='j-article').text.strip()\n",
    "    name=soup.find('span', class_='name').text.strip()\n",
    "    brand=soup.find('span', class_='brand').text.strip()\n",
    "    price = numfromstr(soup.find('span', class_='final-cost').text.strip())\n",
    "    orders_count = numfromstr(soup.find('span', class_='j-orders-count').text.strip())\n",
    "    comments = int(soup.find('a', id=\"comments_reviews_link\").i.text.strip())\n",
    "    rating = int(soup.find('div', class_=\"product-rating\").p.text.strip())\n",
    "    #first_comment = soup.find('div', class_=\"time text-base-gray\").p.text.strip()\n",
    "    browser.find_element_by_link_text('дате').click()\n",
    "    first_comment = browser.find_element_by_class_name('time.text-base-gray').get_attribute('content')\n",
    "    \n",
    "    item = {'article': article, 'brand': brand,'name': name,  'price': price,  'comments': comments,  'orders_count': orders_count,  'rating': rating,  'first_comment': first_comment}\n",
    "    return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    url = 'https://www.wildberries.ru/catalog/0/search.aspx?kind=2&subject=4&search=%D0%BA%D1%83%D0%BF%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%BA%20%D0%B6%D0%B5%D0%BD%D1%81%D0%BA%D0%B8%D0%B9&sort=popular'\n",
    "\n",
    "    # путь к драйверу chrome\n",
    "    firefoxdriver = 'C:\\Work\\drive\\geckodriver.exe'\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.headless = True\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    profile.set_preference(\"general.useragent.override\", UserAgent().random)\n",
    "    \n",
    "    PROXY = get_proxy()['address']\n",
    "    print(PROXY)\n",
    "    \n",
    "    proxy = Proxy({\n",
    "        'proxyType': ProxyType.MANUAL,\n",
    "        'httpProxy': PROXY,\n",
    "        'ftpProxy': PROXY,\n",
    "        'sslProxy': PROXY,\n",
    "        'noProxy':''})\n",
    "    \n",
    "    \n",
    "    browser = webdriver.Firefox(executable_path=firefoxdriver, options=options, proxy=proxy, firefox_profile=profile) \n",
    "    \n",
    "    # you have to use remote, otherwise you'll have to code it yourself in python to \n",
    "    #browser = webdriver.Remote(\"http://localhost:4444/wd/hub\", webdriver.DesiredCapabilities.FIREFOX)\n",
    "\n",
    "\n",
    "    \n",
    "    links = pd.read_csv('links.csv',header=None)[0].tolist()\n",
    "    links = links[:10]\n",
    "    \n",
    "    \n",
    "    i=0\n",
    "    items = []\n",
    "    for link in links:\n",
    "        #print(link)\n",
    "        item = get_item(get_html(link, browser), browser)\n",
    "        #print(item)\n",
    "        items.append(item)\n",
    "        i+=1\n",
    "        if i == int(i/100):\n",
    "            df = pd.DataFrame(items)\n",
    "            df['link']=links\n",
    "            df.to_excel('parsing.xlsx')\n",
    "            print(i)\n",
    "            browser.close()\n",
    "            PROXY = get_proxy()['address']\n",
    "            proxy = Proxy({\n",
    "                'proxyType': ProxyType.MANUAL,\n",
    "                'httpProxy': PROXY,\n",
    "                'ftpProxy': PROXY,\n",
    "                'sslProxy': PROXY,\n",
    "                'noProxy':''})\n",
    "            browser = webdriver.Firefox(executable_path=firefoxdriver, options=options, proxy=proxy, firefox_profile=profile)\n",
    "            \n",
    "    df = pd.DataFrame(items)\n",
    "    df['link']=links\n",
    "    df.to_excel('parsing.xlsx')\n",
    "    \n",
    "    #print(len(links))\n",
    "    #print(links[:10])\n",
    "    \n",
    "    browser.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.99.93.100:43944\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list():\n",
    "    url = 'https://www.wildberries.ru/catalog/0/search.aspx?kind=2&subject=4&search=%D0%BA%D1%83%D0%BF%D0%B0%D0%BB%D1%8C%D0%BD%D0%B8%D0%BA%20%D0%B6%D0%B5%D0%BD%D1%81%D0%BA%D0%B8%D0%B9&sort=popular'\n",
    "\n",
    "    # путь к драйверу chrome\n",
    "    firefoxdriver = 'C:\\Work\\drive\\geckodriver.exe'\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.headless = True\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    profile.set_preference(\"general.useragent.override\", UserAgent().random)\n",
    "\n",
    "    \n",
    "    PROXY = get_proxy()['address']\n",
    "    print(PROXY)\n",
    "    \n",
    "    proxy = Proxy({\n",
    "        'proxyType': ProxyType.MANUAL,\n",
    "        'httpProxy': PROXY,\n",
    "        'ftpProxy': PROXY,\n",
    "        'sslProxy': PROXY,\n",
    "        'noProxy':''})\n",
    "    \n",
    "    browser = webdriver.Firefox(executable_path=firefoxdriver, options=options, proxy=proxy, firefox_profile=profile) \n",
    "    \n",
    "    \n",
    "    links = get_list(url, browser)\n",
    "    \n",
    "    df = pd.DataFrame(links).to_csv('links2.csv', index=False, header=False)\n",
    "\n",
    "    browser.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.164.247.186:53281\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "save_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-08-28T18:02:20.0960000'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.wildberries.ru/catalog/5275302/detail.aspx?targetUrl=SG'\n",
    "\n",
    "    # путь к драйверу chrome\n",
    "firefoxdriver = 'C:\\Work\\drive\\geckodriver.exe'\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.add_argument('headless')  # для открытия headless-браузера\n",
    "options.add_argument(\"window-size=800,400\")\n",
    "options.add_argument(f'user-agent={UserAgent().firefox}')\n",
    "\n",
    "PROXY = get_proxy()['address']\n",
    "    \n",
    "proxy = Proxy({\n",
    "    'proxyType': ProxyType.MANUAL,\n",
    "    'httpProxy': PROXY,\n",
    "    'ftpProxy': PROXY,\n",
    "    'sslProxy': PROXY,\n",
    "    'noProxy':''})\n",
    "    \n",
    "    \n",
    "browser = webdriver.Firefox(executable_path=firefoxdriver, options=options, proxy=proxy) \n",
    "\n",
    "\n",
    "soup = BeautifulSoup(get_html(url, browser), 'html5')\n",
    "browser.find_element_by_link_text('дате').click()\n",
    "s = browser.find_element_by_class_name('time.text-base-gray').get_attribute('content')\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: Unable to locate element: .time text-base-gray\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-6f53f21beb1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time text-base-gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_class_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \"\"\"\n\u001b[1;32m--> 564\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: Unable to locate element: .time text-base-gray\n"
     ]
    }
   ],
   "source": [
    "s = browser.find_element_by_class_name('time text-base-gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('div', class_='time.text-base-gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('script', id=\"productQuestionTmpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<script id=\"productQuestionTmpl\" type=\"text/x-jsrender\">\n",
       "        <div class=\"question\">\n",
       "            <div class=\"question-profile\">\n",
       "                <div class=\"avatar-block\">\n",
       "                    <div class=\"avatar-layout\">\n",
       "                        <img class=\"avatar\" src=\"{{:~wbSettings.staticSiteUrl}}/i/blank.gif\" data-original='{{:~PersonalPhoto(wbUserId, wbUserDetails.hasPhoto)}}' alt=\"avatar\">\n",
       "                    </div>\n",
       "                    <div class=\"country country-{{toLower:wbUserDetails.country}}\">{{:wbUserDetails.country}}</div>\n",
       "                </div>\n",
       "            </div>\n",
       "            <div class=\"question-content\">\n",
       "                <div class=\"question-content-user-and-time\">\n",
       "                    <div itemprop=\"author\" class=\"author\">\n",
       "                        <label data-user-id=\"{{:wbUserId}}\" class=\"text-base-bold\">{{:wbUserDetails.name}}</label>\n",
       "                    </div>\n",
       "                    <div class=\"time text-base-gray\">\n",
       "                        <meta content=\"{{:createdDate}}\">{{:~formatDate(createdDate,'d MMMM yyyy, HH:mm')}}\n",
       "                    </div>\n",
       "                </div>\n",
       "                <p class=\"body\">{{:text}}</p>\n",
       "                <div class=\"reply\">\n",
       "                    <b></b>\n",
       "                    <div class=\"reply-block\">\n",
       "                        <div class=\"reply-block-layout\">\n",
       "                            <div class=\"meta\">\n",
       "                                <span class=\"reply-header\">{{:answer.supplierId > 0 ? \"Представитель бренда\" : \"Wildberries\"}}</span>\n",
       "                                {{if updatedDate}}<span class=\"time\">{{:~formatDate(updatedDate,'d MMMM yyyy, HH:mm')}}</span>{{/if}}\n",
       "                                <div class=\"pros-cons j-b-eval-answer hide\" data-question-id=\"{{:id}}\" data-user-id=\"{{:wbUserId}}\" data-has-complaint=\"{{:!!answerComplaint}}\"></div>\n",
       "                            </div>\n",
       "                            <div class=\"body\">\n",
       "                                <p>{{:answer.text}}</p>\n",
       "                            </div>\n",
       "                        </div>\n",
       "                    </div>\n",
       "                </div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </script>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script\n",
    "re.findall(r'[\\'\\\"]company[\\'\\\"]\\s*\\:\\s*[\\'\\\"]([^\\'\\\"]*)[\\'\\\"]',\n",
    "                       script.text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
